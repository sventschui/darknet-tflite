{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "090138f1",
   "metadata": {},
   "source": [
    "# LegoGears EdgeTPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09bfe81",
   "metadata": {},
   "source": [
    "- Download LegoGears pretrained\n",
    "- Change activation to ReLu and run fine-tuning (Edgetpu does not support LeakyReLu)\n",
    "- Convert to TFLite\n",
    "- Compile for EdgeTPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cb611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env MODEL_DIR=/content/LegoGears_v2_relu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e00aea4",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6925e791",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env DARKNET_VERSION=5.1.82\n",
    "!if [[ ! -d /content/darknet_tflite ]]; then git clone --depth 1 --branch main https://github.com/sventschui/darknet-tflite.git /content/darknet_tflite; fi\n",
    "!/content/darknet_tflite/scripts/install_dependencies.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c4c034",
   "metadata": {},
   "source": [
    "# Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n2z8lhlqorh",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "set -e\n",
    "\n",
    "/content/darknet_tflite/scripts/download_legogears.sh \"${MODEL_DIR}\"\n",
    "\n",
    "cd \"${MODEL_DIR}\"\n",
    "\n",
    "sed -i \"s|/home/stephane/nn/LegoGears|$(pwd)|\" LegoGears.data \n",
    "sed -i \"s|activation=leaky|activation=relu|\" LegoGears.cfg \n",
    "sed -i \"s|batch=1|batch=64|\" LegoGears.cfg "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yi8z2u9vrrh",
   "metadata": {},
   "source": [
    "## Fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe829cd12y",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd \"${MODEL_DIR}\" && darknet detector train \\\n",
    "  LegoGears.data \\\n",
    "  LegoGears.cfg \\\n",
    "  LegoGears_best.weights \\\n",
    "  -map \\\n",
    "  -dont_show \\\n",
    "  -clear\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86efe475",
   "metadata": {},
   "source": [
    "## Copy pre-existing weights (as an alternative to fine tuning yourself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef50400b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cp /content/darknet_tflite/weights/LegoGears_best_relu.weights \"${MODEL_DIR}/LegoGears_best.weights\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ah8zj57virv",
   "metadata": {},
   "source": [
    "## Test the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ookdtoem3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd \"${MODEL_DIR}\"\n",
    "set -e\n",
    "mkdir -p /content/darknet_detections_relu\n",
    "for f in set_03/*.jpg; do\n",
    "  darknet detector test LegoGears.data LegoGears.cfg LegoGears_best.weights \"$f\" -dont_show;\n",
    "  mv predictions.jpg \"/content/darknet_detections_relu/$(basename \"$f\")\";\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ua9zygo49m",
   "metadata": {},
   "source": [
    "## ONNX Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5180f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -e\n",
    "cd \"${MODEL_DIR}\"\n",
    "darknet_onnx_export -noboxes LegoGears.cfg LegoGears_best.weights LegoGears.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee3ef4c",
   "metadata": {},
   "source": [
    "### Run inference with ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46db6d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content\n",
    "import os\n",
    "import cv2\n",
    "import onnxruntime as ort\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import functions\n",
    "functions.reload()\n",
    "\n",
    "DARKNET_MODEL_BASE_NAME = \"LegoGears_v2/LegoGears\"\n",
    "NAMES_FILE = f\"{DARKNET_MODEL_BASE_NAME}.names\"\n",
    "CFG_FILE = f\"{DARKNET_MODEL_BASE_NAME}.cfg\"\n",
    "CONF_THRESHOLD = 0.5\n",
    "IOU_THRESHOLD = 0.45\n",
    "IMAGES_PATH = \"LegoGears_v2/set_03\"\n",
    "\n",
    "# Load class names\n",
    "with open(NAMES_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    class_names = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"✅ Loaded {num_classes} classes\")\n",
    "\n",
    "# Load darknet cfg\n",
    "net, layers = functions.parse_darknet_cfg(CFG_FILE)\n",
    "input_width = net[\"width\"]\n",
    "input_height = net[\"height\"]\n",
    "yolo_layers = [layer for layer in layers if layer[\"type\"] == \"yolo\"]\n",
    "\n",
    "session = ort.InferenceSession(\n",
    "    f\"{DARKNET_MODEL_BASE_NAME}.onnx\", providers=[\"CPUExecutionProvider\"]\n",
    ")\n",
    "\n",
    "for image_name in [img for img in os.listdir(IMAGES_PATH) if img.endswith(\".jpg\")]:\n",
    "    image_path = f\"{IMAGES_PATH}/{image_name}\"\n",
    "\n",
    "    print(f\"Processing image {image_path}\")\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    input_tensor, scale, padding, cv_image = functions.preprocess_image(\n",
    "        input_width, input_height, image\n",
    "    )\n",
    "\n",
    "    print(\"Running inference...\")\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    outputs = session.run(None, {input_name: input_tensor})\n",
    "\n",
    "    print(\"Postprocessing...\")\n",
    "    detections = functions.postprocess_output(\n",
    "        outputs=outputs,\n",
    "        yolo_layers_cfg=yolo_layers,\n",
    "        scale=scale,\n",
    "        input_size=(input_width, input_height),\n",
    "        padding=padding,\n",
    "        class_names=class_names,\n",
    "        conf_threshold=CONF_THRESHOLD,\n",
    "        iou_threshold=IOU_THRESHOLD\n",
    "    )\n",
    "\n",
    "    print(\"Visualize...\")\n",
    "    visualized = functions.visualize_detections(\n",
    "        image=image, detections=detections[0], class_names=class_names\n",
    "    )\n",
    "\n",
    "    plt.imshow(cv2.cvtColor(visualized, cv2.COLOR_BGR2RGB), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplots_adjust(left=0, right=1, top=1, bottom=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5123fc",
   "metadata": {},
   "source": [
    "## TFLite Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa266d9d",
   "metadata": {},
   "source": [
    "### Generate int8 quantization calibration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa35210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import functions\n",
    "functions.reload()\n",
    "\n",
    "DARKNET_CONFIG_PATH = f\"{os.environ.get(\"MODEL_DIR\")}/LegoGears.cfg\"\n",
    "IMAGES_PATH = f\"{os.environ.get(\"MODEL_DIR\")}/set_03\"\n",
    "\n",
    "net, layers = functions.parse_darknet_cfg(DARKNET_CONFIG_PATH)\n",
    "\n",
    "files = glob.glob(f\"{IMAGES_PATH}/*.jpg\")\n",
    "images = []\n",
    "for idx, file in enumerate(files):\n",
    "    img = cv2.imread(file)\n",
    "    img = cv2.resize(img, dsize=(net[\"width\"], net[\"height\"]))\n",
    "    img = img.astype(np.float32) / 255.0  # convert to 0.0 - 1.0 scale\n",
    "    images.append(img)\n",
    "\n",
    "np.save(file=f\"{IMAGES_PATH}/calibdata.npy\", arr=np.stack(images, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43224b6f",
   "metadata": {},
   "source": [
    "### Convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c8931b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd \"${MODEL_DIR}\" && rm -f *.tflite && onnx2tf -i LegoGears.onnx \\\n",
    "    -oiqt \\\n",
    "    -o \"${MODEL_DIR}\"  \\\n",
    "    -cind \"frame\" \"set_03/calibdata.npy\" \"[[[[0,0,0]]]]\" \"[[[[1,1,1]]]]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056d98b9",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25b9001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from ai_edge_litert.interpreter import Interpreter, load_delegate  # AI Edge Lite / TFLite Runtime\n",
    "# from tensorflow.lite import Interpreter  # Uncomment if using full TensorFlow instead\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import functions\n",
    "functions.reload()\n",
    "\n",
    "def load_interpreter(model_path, use_edgetpu=False):\n",
    "    \"\"\"\n",
    "    Load a TensorFlow Lite or EdgeTPU interpreter.\n",
    "    \"\"\"\n",
    "    if use_edgetpu:\n",
    "        delegates = [load_delegate('libedgetpu.so.1')]\n",
    "        interpreter = Interpreter(model_path=model_path, experimental_delegates=delegates)\n",
    "    else:\n",
    "        interpreter = Interpreter(model_path=model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "    return interpreter\n",
    "\n",
    "def dequant(tensor, details):\n",
    "    if details[\"dtype\"] != np.float32:\n",
    "        scale_out, zero_point_out = details['quantization']\n",
    "\n",
    "        return (tensor.astype(np.float32) - zero_point_out) * scale_out\n",
    "    \n",
    "    return tensor\n",
    "\n",
    "def run_inference_tflite(model_path, image, yolo_layers, class_names, use_edgetpu=False):\n",
    "    \"\"\"\n",
    "    Run inference on a single image using a TFLite/AI Edge Lite model.\n",
    "    \"\"\"\n",
    "    # Load the model\n",
    "    interpreter = load_interpreter(model_path, use_edgetpu)\n",
    "\n",
    "    # Get input & output details\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    input_shape = input_details[0]['shape']\n",
    "    batch_size, input_height, input_width, channels = input_shape\n",
    "\n",
    "    # Preprocess image\n",
    "    input_data, scale, padding, original_image = functions.preprocess_image(input_width, input_height, image)\n",
    "\n",
    "\n",
    "    # NCHW -> NHWC\n",
    "    input_data = np.transpose(input_data, (0, 2, 3, 1))\n",
    "\n",
    "    if input_details[0][\"dtype\"] != np.float32:\n",
    "        quant_scale, quant_zero = input_details[0]['quantization']\n",
    "\n",
    "        input_data = (input_data.astype(np.float32) / quant_scale + quant_zero).round().astype(input_details[0][\"dtype\"])\n",
    "\n",
    "        # TODO: Detect output reversion instead of just assuming it for int8\n",
    "        yolo_layers = list(reversed(yolo_layers))\n",
    "\n",
    "    # Run inference\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    start_time = time.time()\n",
    "    interpreter.invoke()\n",
    "    inference_time = (time.time() - start_time) * 1000  # ms\n",
    "\n",
    "\n",
    "    # Gather outputs (NHWC -> NCHW)\n",
    "    outputs = [np.transpose(dequant(interpreter.get_tensor(o['index']), o), (0, 3, 1, 2)) for o in output_details]\n",
    "\n",
    "\n",
    "    # Postprocess    \n",
    "    print(\"Postprocessing...\")\n",
    "    detections = functions.postprocess_output(\n",
    "        outputs,\n",
    "        yolo_layers_cfg=yolo_layers,\n",
    "        input_size=(input_width, input_height),\n",
    "        conf_threshold=CONF_THRESHOLD,\n",
    "        iou_threshold=IOU_THRESHOLD,\n",
    "        scale=scale,\n",
    "        padding=padding,\n",
    "        class_names=class_names,\n",
    "    )\n",
    "\n",
    "    print(f\"Inference completed in {inference_time:.2f} ms\")\n",
    "    return detections\n",
    "\n",
    "\n",
    "NAMES_FILE=f\"{os.environ.get(\"MODEL_DIR\")}/LegoGears.names\"\n",
    "CFG_FILE=f\"{os.environ.get(\"MODEL_DIR\")}/LegoGears.cfg\"\n",
    "# TF_MODEL=f\"{os.environ.get(\"MODEL_DIR\")}/LegoGears_float32.tflite\"\n",
    "TF_MODEL=f\"{os.environ.get(\"MODEL_DIR\")}/LegoGears_full_integer_quant.tflite\"\n",
    "CONF_THRESHOLD=0.25\n",
    "IOU_THRESHOLD=0.45\n",
    "IMAGES_PATH=f\"{os.environ.get(\"MODEL_DIR\")}/set_03\"\n",
    "\n",
    "# Load class names\n",
    "with open(NAMES_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    class_names = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"✅ Loaded {num_classes} classes\")\n",
    "\n",
    "# Load darknet cfg\n",
    "net, layers = functions.parse_darknet_cfg(CFG_FILE)\n",
    "yolo_layers = [layer for layer in layers if layer['type'] == 'yolo']\n",
    "\n",
    "for image_name in [img for img in os.listdir(IMAGES_PATH) if img.endswith('.jpg')]:\n",
    "    image_path = f\"{IMAGES_PATH}/{image_name}\"\n",
    "\n",
    "    print(f\"Processing image {image_path}\")\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    print(\"Running inference...\")\n",
    "    detections = run_inference_tflite(TF_MODEL, image=image, \n",
    "                                      yolo_layers=yolo_layers,\n",
    "        class_names=class_names,\n",
    "                                      \n",
    "                                      use_edgetpu=False)\n",
    "\n",
    "\n",
    "    print(\"Visualize...\")\n",
    "    visualized = functions.visualize_detections(\n",
    "        image=image,\n",
    "        detections=detections[0],\n",
    "        class_names=class_names\n",
    "    )\n",
    "\n",
    "    plt.imshow(cv2.cvtColor(visualized, cv2.COLOR_BGR2RGB),cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplots_adjust(left=0, right=1, top=1, bottom=0)\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8967a15d",
   "metadata": {},
   "source": [
    "## Compile for edgetpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2bcb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env EDGETPU_COMPILER_MODEL_INPUT=LegoGears_full_integer_quant.tflite\n",
    "!cd \"${MODEL_DIR}\" && edgetpu_compiler \"${EDGETPU_COMPILER_MODEL_INPUT}\" --show_operations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
